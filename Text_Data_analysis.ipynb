{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text-Data-analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcf010iwvH/T9JQzWVC1rr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "lbJxV_ObWrar",
        "outputId": "22d085d8-c425-4c91-e694-e8ce41f33aea"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c8e3e66d-68ac-4308-8de2-9439a548bff4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c8e3e66d-68ac-4308-8de2-9439a548bff4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Вопросы карьеры.csv to Вопросы карьеры.csv\n",
            "Saving Вредные привычки, зависимость.csv to Вредные привычки, зависимость.csv\n",
            "Saving Горе, потери.csv to Горе, потери.csv\n",
            "Saving Депрессия.csv to Депрессия.csv\n",
            "Saving Нервные расстройства.csv to Нервные расстройства.csv\n",
            "Saving О достижении цели.csv to О достижении цели.csv\n",
            "Saving Отношения с окружающими.csv to Отношения с окружающими.csv\n",
            "Saving Поиск решения.csv to Поиск решения.csv\n",
            "Saving Проблемы с детьми.csv to Проблемы с детьми.csv\n",
            "Saving Проблемы с партнером.csv to Проблемы с партнером.csv\n",
            "Saving Размышления о мире.csv to Размышления о мире.csv\n",
            "Saving Самопознание, саморазвитие.csv to Самопознание, саморазвитие.csv\n",
            "Saving Семейные проблемы.csv to Семейные проблемы.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0waXMh-YLZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1620a68b-374b-48a2-afab-3c9cdce1913e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " sample_data\t\t\t     'Отношения с окружающими.csv'\n",
            "'Вопросы карьеры.csv'\t\t     'Поиск решения.csv'\n",
            "'Вредные привычки, зависимость.csv'  'Проблемы с детьми.csv'\n",
            "'Горе, потери.csv'\t\t     'Проблемы с партнером.csv'\n",
            " Депрессия.csv\t\t\t     'Размышления о мире.csv'\n",
            "'Нервные расстройства.csv'\t     'Самопознание, саморазвитие.csv'\n",
            "'О достижении цели.csv'\t\t     'Семейные проблемы.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnJ9ru3CZHGl"
      },
      "source": [
        "Let's create 2 files: training and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUrGy-bgaJUN"
      },
      "source": [
        "test data - 20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuGh5bdWmcf3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_icK_-bYt7N"
      },
      "source": [
        "extension = 'csv'\n",
        "file_names = [i for i in glob.glob('*.{}'.format(extension))]\n",
        "file_names_size = len(file_names);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux7CCHhpaARl"
      },
      "source": [
        "Let's mark the data: add a column in which the value will mean the category number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHW2CGIUae4m"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3WdhW7dY1xh"
      },
      "source": [
        "data_train = []\n",
        "data_test = []\n",
        "\n",
        "i = 0\n",
        "while i<file_names_size:\n",
        "  df = pd.read_csv(file_names[i], header=0)\n",
        "  df['THEME'] = i\n",
        "  train, test = train_test_split(df, test_size=0.2)\n",
        "  data_train.append(train)\n",
        "  data_test.append(test)\n",
        "  i = i + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "RK8YXiT4aWQ0",
        "outputId": "d22abda3-b718-4614-aa9c-c6e1e0aba931"
      },
      "source": [
        "data_test[7][:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>USER_ID</th>\n",
              "      <th>USER_NICKNAME</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>MESSAGE</th>\n",
              "      <th>DATE_TIME</th>\n",
              "      <th>TOPIC_LIKES_COUNT</th>\n",
              "      <th>URL</th>\n",
              "      <th>THEME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>390</td>\n",
              "      <td>u455467</td>\n",
              "      <td>Takanika</td>\n",
              "      <td>Как объяснить ребёнку развод</td>\n",
              "      <td>Добрый день! Ситуация такая: имеется дочь 2 ле...</td>\n",
              "      <td>2019-08-28 16:14</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.b17.ru/forum/topic.php?id=178090</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>215</td>\n",
              "      <td>u479450</td>\n",
              "      <td>kapella17</td>\n",
              "      <td>Панически боюсь заводить ребенка.</td>\n",
              "      <td>Здравствуйте. Мне 27 лет, замужем шестой год. ...</td>\n",
              "      <td>2019-11-28 10:02</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.b17.ru/forum/topic.php?id=191222</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>372</td>\n",
              "      <td>u257473</td>\n",
              "      <td>Вопрос ительница</td>\n",
              "      <td>Адаптация к яслям</td>\n",
              "      <td>Здравствуйте, уважаемые специалисты! Сейчас мн...</td>\n",
              "      <td>2019-09-04 13:58</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.b17.ru/forum/topic.php?id=179024</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  USER_ID  ...                                           URL THEME\n",
              "390         390  u455467  ...  https://www.b17.ru/forum/topic.php?id=178090     7\n",
              "215         215  u479450  ...  https://www.b17.ru/forum/topic.php?id=191222     7\n",
              "372         372  u257473  ...  https://www.b17.ru/forum/topic.php?id=179024     7\n",
              "\n",
              "[3 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "Ovu9JBTTayz5",
        "outputId": "04728285-a6a7-4b54-9ddb-c7aad5d410da"
      },
      "source": [
        "data_train[2][:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>USER_ID</th>\n",
              "      <th>USER_NICKNAME</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>MESSAGE</th>\n",
              "      <th>DATE_TIME</th>\n",
              "      <th>TOPIC_LIKES_COUNT</th>\n",
              "      <th>URL</th>\n",
              "      <th>THEME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>649</th>\n",
              "      <td>649</td>\n",
              "      <td>u599594</td>\n",
              "      <td>Maruisa</td>\n",
              "      <td>Какой тип темперамента???</td>\n",
              "      <td>Здравствуйте! Очень интересует вопрос о собств...</td>\n",
              "      <td>2020-02-13 13:03</td>\n",
              "      <td>3</td>\n",
              "      <td>https://www.b17.ru/forum/topic.php?id=302482</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1008</th>\n",
              "      <td>1008</td>\n",
              "      <td>u239380</td>\n",
              "      <td>Наташа46</td>\n",
              "      <td>Конфликт на работе</td>\n",
              "      <td>Прошу помощи!Обещаю помогать при работе)Очень ...</td>\n",
              "      <td>2019-12-08 07:54</td>\n",
              "      <td>2</td>\n",
              "      <td>https://www.b17.ru/forum/topic.php?id=192676</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>490</td>\n",
              "      <td>u606530</td>\n",
              "      <td>Георцина</td>\n",
              "      <td>Как выбирать кого-то с сайтов знакомств ?</td>\n",
              "      <td>Если мужчины все одинаковые?Вот допустим встре...</td>\n",
              "      <td>2020-03-11 15:21</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.b17.ru/forum/topic.php?id=306220</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  USER_ID  ...                                           URL THEME\n",
              "649          649  u599594  ...  https://www.b17.ru/forum/topic.php?id=302482     2\n",
              "1008        1008  u239380  ...  https://www.b17.ru/forum/topic.php?id=192676     2\n",
              "490          490  u606530  ...  https://www.b17.ru/forum/topic.php?id=306220     2\n",
              "\n",
              "[3 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NftWC1-VbqG-"
      },
      "source": [
        "combining the data into a single file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XHOHmhTbsI-"
      },
      "source": [
        "-train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08bFG3x5biOm"
      },
      "source": [
        "final_data_train = pd.concat(data_train)\n",
        "final_data_train.to_csv( 'train.csv', index=False, encoding='utf-8-sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXNU6da2b_DG",
        "outputId": "a605fd30-c385-484d-ae39-a6691afac9ec"
      },
      "source": [
        "!wc -l train.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29530 train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ973py5bz_N"
      },
      "source": [
        "-test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJJKG-LMbyrV"
      },
      "source": [
        "final_data_test = pd.concat(data_test)\n",
        "final_data_test.to_csv( \"test.csv\", index=False, encoding='utf-8-sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNw4lUqDcAll",
        "outputId": "6d3162c1-212d-418d-a393-9386ddb4ada9"
      },
      "source": [
        "!wc -l test.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2642 test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "pY8hmBeCcEXG",
        "outputId": "9ee78073-a603-433b-9d1e-b34040aa0343"
      },
      "source": [
        "train = pd.read_csv('train.csv', header=0)\n",
        "train[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>USER_ID</th>\n",
              "      <th>USER_NICKNAME</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>MESSAGE</th>\n",
              "      <th>DATE_TIME</th>\n",
              "      <th>TOPIC_LIKES_COUNT</th>\n",
              "      <th>URL</th>\n",
              "      <th>THEME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>829</td>\n",
              "      <td>u468698</td>\n",
              "      <td>EvaMenfri</td>\n",
              "      <td>Личность расщепляется</td>\n",
              "      <td>Привет. Мне 18 лет. Я переезжала 4 раза за сво...</td>\n",
              "      <td>2019-10-20 22:00</td>\n",
              "      <td>2</td>\n",
              "      <td>https://www.b17.ru/forum/topic.php?id=185499</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>889</td>\n",
              "      <td>u465247</td>\n",
              "      <td>Наталия #465247</td>\n",
              "      <td>ПА, депрессия, проблемы с мамой</td>\n",
              "      <td>Здравствуйте. Полгода назад начались лёгкие пе...</td>\n",
              "      <td>2019-10-08 17:43</td>\n",
              "      <td>2</td>\n",
              "      <td>https://www.b17.ru/forum/topic.php?id=183697</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>935</td>\n",
              "      <td>u459309</td>\n",
              "      <td>Lena_905435</td>\n",
              "      <td>Нервное расстройство мамы</td>\n",
              "      <td>Добрый день! Я мама двоих детей 6 и два года. ...</td>\n",
              "      <td>2019-09-24 16:53</td>\n",
              "      <td>0</td>\n",
              "      <td>https://www.b17.ru/forum/topic.php?id=181727</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  USER_ID  ...                                           URL THEME\n",
              "0         829  u468698  ...  https://www.b17.ru/forum/topic.php?id=185499     0\n",
              "1         889  u465247  ...  https://www.b17.ru/forum/topic.php?id=183697     0\n",
              "2         935  u459309  ...  https://www.b17.ru/forum/topic.php?id=181727     0\n",
              "\n",
              "[3 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "DhCq2Ji0cPE2",
        "outputId": "592b8fc7-5b90-4200-bdb4-98c901e88aff"
      },
      "source": [
        "test = pd.read_csv('test.csv', header=0)\n",
        "test[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>USER_ID</th>\n",
              "      <th>USER_NICKNAME</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>MESSAGE</th>\n",
              "      <th>DATE_TIME</th>\n",
              "      <th>TOPIC_LIKES_COUNT</th>\n",
              "      <th>URL</th>\n",
              "      <th>THEME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82</td>\n",
              "      <td>u622719</td>\n",
              "      <td>Julia555</td>\n",
              "      <td>Как справится с приступом ипохондрии?</td>\n",
              "      <td>Доброго времени суток!Уважаемые специалисты, к...</td>\n",
              "      <td>2020-05-13 18:32</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.b17.ru/forum/topic.php?id=314622</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43</td>\n",
              "      <td>u622778</td>\n",
              "      <td>Anastezija</td>\n",
              "      <td>РПП</td>\n",
              "      <td>Добрый день, меня зовут Ася, мне 25 лет. Работ...</td>\n",
              "      <td>2020-05-13 23:01</td>\n",
              "      <td>0</td>\n",
              "      <td>https://www.b17.ru/forum/topic.php?id=314660</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42</td>\n",
              "      <td>u429648</td>\n",
              "      <td>Евгения312</td>\n",
              "      <td>Окр</td>\n",
              "      <td>Здравствуйте Валерий Юрьевич.Моя проблема что ...</td>\n",
              "      <td>2020-02-10 19:26</td>\n",
              "      <td>4</td>\n",
              "      <td>https://www.b17.ru/forum/topic.php?id=302072</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  USER_ID  ...                                           URL THEME\n",
              "0          82  u622719  ...  https://www.b17.ru/forum/topic.php?id=314622     0\n",
              "1          43  u622778  ...  https://www.b17.ru/forum/topic.php?id=314660     0\n",
              "2          42  u429648  ...  https://www.b17.ru/forum/topic.php?id=302072     0\n",
              "\n",
              "[3 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBkx3DzIc6pf"
      },
      "source": [
        "from tensorflow.keras import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "ekFXlbzsic0o",
        "outputId": "6347914c-291b-4de1-a657-f8486156f6b7"
      },
      "source": [
        "trb_nan_idx = train[pd.isnull(train['MESSAGE'])].index.tolist()\n",
        "train.loc[trb_nan_idx, 'MESSAGE'] = ' '\n",
        "train.loc[trb_nan_idx, 'MESSAGE'] = ' '"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-159-4ad91060cd97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrb_nan_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MESSAGE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrb_nan_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MESSAGE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrb_nan_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MESSAGE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "XTzU4TtjcqL5",
        "outputId": "4e061dab-7993-4582-d8c1-5f3a7a823cfe"
      },
      "source": [
        "x_train = train['MESSAGE']\n",
        "y_train = utils.to_categorical(train['THEME'],file_names_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-158-85dd8ba244ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MESSAGE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'THEME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_names_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "migN61LLilCY",
        "outputId": "99c66092-2fc6-4293-bb5f-03d6c11d584c"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"russian\")\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw7LdypVioYd"
      },
      "source": [
        "def token_and_stem(text):\n",
        "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if re.search('[а-яА-Я]', token):\n",
        "            filtered_tokens.append(token)\n",
        "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
        "    print(type(stems))\n",
        "    return stems"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi5N6QZKi09K"
      },
      "source": [
        "upd_x_train = []\n",
        "i = 0\n",
        "\n",
        "while i<file_names_size:\n",
        "  upd_train = token_and_stem(x_train[i])\n",
        "  upd_x_train.append(upd_train)\n",
        "  i = i + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpiXBXeWjgLd",
        "outputId": "98629fba-bd15-44d6-c637-9ce8dc7e7cd3"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('russian')\n",
        "#можно расширить список стоп-слов\n",
        "stopwords.extend(['что', 'это', 'так', 'вот', 'быть', 'как', 'в', 'к', 'на'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPkEmW6zjv_m"
      },
      "source": [
        "tokens = []\n",
        "train = []\n",
        "\n",
        "for x_tr in upd_x_train:\n",
        "  for token in x_tr:\n",
        "    if token not in stopwords:\n",
        "      tokens.append(token)\n",
        "  train.append(tokens)\n",
        "  tokens = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0_nRqVzfnWw",
        "outputId": "be661ee1-19f3-4f3c-baae-b016ec945107"
      },
      "source": [
        "x_train[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2741,   19,  390,    5,    7, 1426,    3,   38,  512, 1096,    8,\n",
              "          98,  481,  124,    3,  106,  758,    3,   36,  828,   20,  454,\n",
              "           4,   54,   36,  828,    6, 3778,   10,  958,  528,   13,   31,\n",
              "           3,  769,  180,   71,   22, 2330,  293,    3,   38,  270, 2742,\n",
              "         292,  135,    3,  189, 1375,    4,  203,  484,   17, 1533,    6,\n",
              "           1,  182,    3,  302,    5,   23,  121,  962,    2,  959,   63,\n",
              "          67,   73,   35,    3,    8,  152,    2, 4507, 1376,    5,   23,\n",
              "          11,  959,   13,  552,   13,    1,  175,  758,  259,   12,  249,\n",
              "           3,    2,   36,   18,   73, 3715,    3,   40, 1427,   12,   22,\n",
              "         650],\n",
              "       [  24, 1450, 4807,   73,    2, 3380,    7,   11,    1,  877,  324,\n",
              "           3,    2,   40,  174,  216,  475,   38, 2507,   27,  366, 1186,\n",
              "        1589,   18,    3,   75,   11, 3045,    4,  267, 3129,  379,  142,\n",
              "           4,  536,  154,    2,  267,  868,  209,   12,   45,    1, 2956,\n",
              "          41,  125,  140,    5,  329,    1,   10,   13,    8,    9,    2,\n",
              "          36,    6,  379,  224,   12,    2, 1309,    8,    6, 4043,  299,\n",
              "           4,  953, 1430,   12,  107,  173,   48, 4337,   23, 1113,   23,\n",
              "         793,  495, 4337,   23,  300,  620,    5,    3,  570,    8,   40,\n",
              "        2242,   10,    2,  218,  131, 1031,  124,  725,  182, 1451,    1,\n",
              "        1068],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,  137,   54,    3,  142, 2996,  183,    1,  245,   70,    4,\n",
              "        1085, 2887,  878,    8,   45,  311,    6,  351,  714,  124,  652,\n",
              "         407,   15,    3, 3597,  116,    3,  290,    1, 1091,    3,   61,\n",
              "           5,   13,  167,  370,    1,    3,  270,   41,  297,   10,   17,\n",
              "         235,    2,  218,  124, 1472,   64,    8,   25,   57,    2,   55,\n",
              "          10,    8,  370, 2887,    4, 1085,   15,    3,  115,   17,   41,\n",
              "         244,  544,    6,  351,  124,  130,    7,   31,  106,    7,  176,\n",
              "        2217,  576, 1291,   30,   71,  148,    1,  301, 1413,    8,   61,\n",
              "         250]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guK5gT_kz1mp",
        "outputId": "9dc2c056-1ab3-4d69-92a8-3728c502368d"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2741,   19,  390, ...,   12,   22,  650],\n",
              "       [  24, 1450, 4807, ..., 1451,    1, 1068],\n",
              "       [   0,    0,    0, ...,    8,   61,  250],\n",
              "       ...,\n",
              "       [  96,   86,    6, ...,    1,    2, 2989],\n",
              "       [ 255,   59, 4387, ...,  319,    4,   61],\n",
              "       [   0,    0,    0, ..., 1460,    6,    1]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTYRpZ6kcyTO"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqznwsMfdLnn"
      },
      "source": [
        "num_words = 5000\n",
        "tokenizer = Tokenizer(num_words=num_words, filters='0123456789!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
        "upd_tokenizer = Tokenizer(num_words=num_words, filters='0123456789!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uh0DenSge4x"
      },
      "source": [
        "tokenizer.fit_on_texts(x_train)\n",
        "upd_tokenizer.fit_on_texts(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9jzSjz0dUHV"
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l76nU7t5kJg6"
      },
      "source": [
        "upd_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbhjO4bFjNMx"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(x_train)\n",
        "upd_sequences = upd_tokenizer.texts_to_sequences(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fmOdr_kjdcI",
        "outputId": "f61705ae-4f41-4d96-e16b-f2015c21ff69"
      },
      "source": [
        "print(x_train[0])\n",
        "print(sequences[0])\n",
        "print(train[0])\n",
        "print(upd_sequences[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Привет. Мне 18 лет. Я переезжала 4 раза за свою жизнь в разные города.Уже 3 год меня не покидает комок в горле, ненависть к себе,  родителям и всему живому и вечная скованность с другими людьми.  У меня есть друзья, но никто из них не знает о моих настоящих чувствах. С ними я веду себя всегда как клоун, чтоб им было весело. Рассказать о настоящем для меня сложнее, чем поднять 10 тонную тяжесть. Слишком стыдно, и меня уж точно никто не поймет. Я постоянно притворяюсь, играю какие-то роли. Пытаюсь возненавидеть тех, кто мне нравится (так как не могу с ними общаться), и при этом снаружи я стараюсь им понравится и угодить. В этот момент я выгляжу примерно как камень, который старается корчить \"лыбу\" и говорить \"приятные\" слова. Я лицемерка.На улицу выходить мне тяжело, всегда складывается ощущение, что мне нужно соответствовать каким-то стандартам. Это приводит к тому, что на улицу я просто стараюсь выходить как можно меньше. Дома я постоянно плачу. Я могу плакать по 3 раза в день. Могу плакать с каменным лицом, но слезы будут течь. Это уже привычная эмоция.Я ненавижу счастливых людей, они выглядят очень глупо. Наверное, я просто им завидую.Неделю назад я снова переехала в другой город. Все заново , с чистого листа.И тогда я поняла, что от моей личности не осталось ровным счетом ничего. Ее больше нет, я как будто не существую. Единственное, что от меня осталось - это оболочка. Пишу это и опять плачу. Помогите мне, пожалуйста. Я не могу так больше существовать. Я хочу умереть, мне очень трудно.\n",
            "[867, 12, 39, 3, 454, 21, 160, 91, 4, 509, 1112, 31, 141, 11, 2, 4707, 4, 2540, 1803, 19, 61, 748, 1, 816, 1, 6, 654, 327, 14, 11, 34, 513, 10, 279, 29, 176, 2, 473, 42, 341, 1616, 6, 351, 3, 1532, 25, 83, 8, 328, 270, 28, 2773, 1084, 42, 44, 11, 2241, 74, 2845, 4114, 356, 641, 1, 11, 646, 433, 279, 2, 3228, 3, 106, 2567, 164, 9, 2279, 360, 355, 104, 12, 255, 18, 8, 2, 36, 6, 351, 232, 1, 85, 69, 3, 512, 270, 3271, 1, 4, 134, 159, 3, 2216, 520, 8, 166, 2256, 1, 284, 3953, 371, 3, 7, 1426, 1096, 12, 274, 83, 2169, 271, 5, 12, 107, 598, 9, 13, 2741, 19, 390, 5, 7, 1426, 3, 38, 512, 1096, 8, 98, 481, 124, 3, 106, 758, 3, 36, 828, 20, 454, 4, 54, 36, 828, 6, 3778, 10, 958, 528, 13, 31, 3, 769, 180, 71, 22, 2330, 293, 3, 38, 270, 2742, 292, 135, 3, 189, 1375, 4, 203, 484, 17, 1533, 6, 1, 182, 3, 302, 5, 23, 121, 962, 2, 959, 63, 67, 73, 35, 3, 8, 152, 2, 4507, 1376, 5, 23, 11, 959, 13, 552, 13, 1, 175, 758, 259, 12, 249, 3, 2, 36, 18, 73, 3715, 3, 40, 1427, 12, 22, 650]\n",
            "['привет', 'лет', 'переезжа', 'сво', 'жизн', 'разн', 'города.уж', 'год', 'мен', 'покида', 'комок', 'горл', 'ненавист', 'себ', 'родител', 'всем', 'жив', 'вечн', 'скован', 'друг', 'людьм', 'мен', 'ест', 'друз', 'никт', 'знает', 'мо', 'настоя', 'чувств', 'вед', 'себ', 'всегд', 'клоун', 'весел', 'рассказа', 'настоя', 'мен', 'сложн', 'подня', 'тон', 'тяжест', 'слишк', 'стыдн', 'мен', 'точн', 'никт', 'поймет', 'постоя', 'притворя', 'игра', 'какие-т', 'рол', 'пыта', 'возненавидет', 'тех', 'нрав', 'мог', 'обща', 'эт', 'снаруж', 'стара', 'понрав', 'угод', 'момент', 'выгляж', 'примерн', 'камен', 'котор', 'стара', 'корч', 'лыб', 'говор', 'приятн', 'слов', 'лицемерка.н', 'улиц', 'выход', 'тяжел', 'всегд', 'складыва', 'ощущен', 'нужн', 'соответствова', 'каким-т', 'стандарт', 'эт', 'привод', 'улиц', 'прост', 'стара', 'выход', 'можн', 'меньш', 'дом', 'постоя', 'плач', 'мог', 'плака', 'ден', 'мог', 'плака', 'камен', 'лиц', 'слез', 'будут', 'теч', 'эт', 'привычн', 'эмоция.', 'ненавиж', 'счастлив', 'люд', 'выгляд', 'очен', 'глуп', 'наверн', 'прост', 'завидую.недел', 'назад', 'снов', 'перееха', 'друг', 'город', 'занов', 'чист', 'листа.', 'тогд', 'поня', 'мо', 'личност', 'оста', 'ровн', 'счет', 'нич', 'е', 'больш', 'будт', 'существ', 'единствен', 'мен', 'оста', 'эт', 'оболочк', 'пиш', 'эт', 'опя', 'плач', 'помог', 'пожалуйст', 'мог', 'больш', 'существова', 'хоч', 'умерет', 'очен', 'трудн']\n",
            "[327, 17, 328, 22, 23, 170, 329, 7, 2, 330, 171, 172, 331, 4, 107, 173, 53, 332, 333, 10, 174, 2, 54, 175, 176, 108, 3, 177, 24, 178, 4, 109, 334, 335, 336, 177, 2, 110, 337, 338, 339, 340, 341, 2, 342, 176, 343, 14, 344, 55, 345, 346, 347, 348, 179, 349, 11, 39, 1, 350, 111, 351, 352, 180, 353, 181, 182, 12, 111, 354, 355, 18, 356, 27, 357, 56, 112, 78, 109, 358, 359, 79, 360, 183, 361, 1, 184, 56, 40, 111, 112, 41, 362, 19, 14, 185, 11, 113, 28, 11, 113, 182, 363, 364, 365, 366, 1, 367, 368, 369, 370, 20, 371, 29, 372, 373, 40, 374, 42, 186, 375, 10, 376, 377, 187, 378, 188, 80, 3, 81, 114, 379, 115, 57, 13, 35, 189, 380, 381, 2, 114, 1, 382, 383, 1, 384, 185, 190, 191, 11, 35, 385, 21, 386, 29, 387]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JFE_q4Sj4iJ"
      },
      "source": [
        "max_text_len = 100\n",
        "x_train = pad_sequences(sequences, maxlen=max_text_len)\n",
        "upd_x_train = pad_sequences(upd_sequences, maxlen=max_text_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5XCrfPekGHg",
        "outputId": "a38bef1a-feb5-468f-83fe-5ca5cc29dc07"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2741,   19,  390,    5,    7, 1426,    3,   38,  512, 1096,    8,\n",
              "         98,  481,  124,    3,  106,  758,    3,   36,  828,   20,  454,\n",
              "          4,   54,   36,  828,    6, 3778,   10,  958,  528,   13,   31,\n",
              "          3,  769,  180,   71,   22, 2330,  293,    3,   38,  270, 2742,\n",
              "        292,  135,    3,  189, 1375,    4,  203,  484,   17, 1533,    6,\n",
              "          1,  182,    3,  302,    5,   23,  121,  962,    2,  959,   63,\n",
              "         67,   73,   35,    3,    8,  152,    2, 4507, 1376,    5,   23,\n",
              "         11,  959,   13,  552,   13,    1,  175,  758,  259,   12,  249,\n",
              "          3,    2,   36,   18,   73, 3715,    3,   40, 1427,   12,   22,\n",
              "        650], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lref3P5Klt_r",
        "outputId": "c9c89541-aad9-436f-c047-df46c0299a40"
      },
      "source": [
        "upd_x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 11,  39,   1, 350, 111, 351, 352, 180, 353, 181, 182,  12, 111,\n",
              "       354, 355,  18, 356,  27, 357,  56, 112,  78, 109, 358, 359,  79,\n",
              "       360, 183, 361,   1, 184,  56,  40, 111, 112,  41, 362,  19,  14,\n",
              "       185,  11, 113,  28,  11, 113, 182, 363, 364, 365, 366,   1, 367,\n",
              "       368, 369, 370,  20, 371,  29, 372, 373,  40, 374,  42, 186, 375,\n",
              "        10, 376, 377, 187, 378, 188,  80,   3,  81, 114, 379, 115,  57,\n",
              "        13,  35, 189, 380, 381,   2, 114,   1, 382, 383,   1, 384, 185,\n",
              "       190, 191,  11,  35, 385,  21, 386,  29, 387], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjfwyVfGkV1q"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, MaxPooling1D, Conv1D, GlobalMaxPooling1D, Dropout, LSTM, GRU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdGkbLSokh7A"
      },
      "source": [
        "model_cnn = Sequential()\n",
        "model_cnn.add(Embedding(num_words, 32, input_length=max_text_len))\n",
        "model_cnn.add(Conv1D(3*file_names_size**2, 5, padding='valid', activation='relu'))\n",
        "model_cnn.add(GlobalMaxPooling1D())\n",
        "model_cnn.add(Dense(file_names_size**2, activation='relu'))\n",
        "model_cnn.add(Dense(file_names_size, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL8CmjUakmfg"
      },
      "source": [
        "model_cnn.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya0FOCYtlUjj",
        "outputId": "71f144c4-25b1-4fb1-af23-983d3a7d9fc3"
      },
      "source": [
        "model_cnn.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 100, 32)           160000    \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 96, 507)           81627     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 507)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 169)               85852     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 13)                2210      \n",
            "=================================================================\n",
            "Total params: 329,689\n",
            "Trainable params: 329,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzIJyrVFmYlu"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKI3Xwx3lZXZ"
      },
      "source": [
        "model_cnn_save_path = 'best_model_cnn.h5'\n",
        "checkpoint_callback_cnn = ModelCheckpoint(model_cnn_save_path, \n",
        "                                      monitor='val_accuracy',\n",
        "                                      save_best_only=True,\n",
        "                                      verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIyDSYyZl_bL"
      },
      "source": [
        "upd_model_cnn_save_path = 'upd_best_model_cnn.h5'\n",
        "upd_checkpoint_callback_cnn = ModelCheckpoint(upd_model_cnn_save_path, \n",
        "                                      monitor='val_accuracy',\n",
        "                                      save_best_only=True,\n",
        "                                      verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ISZxwAmtZ7",
        "outputId": "b29e9a21-525a-44ed-9614-128ede394266"
      },
      "source": [
        "history_cnn = model_cnn.fit(x_train, \n",
        "                            y_train, \n",
        "                            epochs=50,\n",
        "                            batch_size=256,\n",
        "                            validation_split=0.2,\n",
        "                            callbacks=[checkpoint_callback_cnn])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "33/33 [==============================] - 13s 366ms/step - loss: 2.4496 - accuracy: 0.0976 - val_loss: 5.4672 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.00000, saving model to best_model_cnn.h5\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 2.3629 - accuracy: 0.1353 - val_loss: 6.7745 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.00000\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 12s 361ms/step - loss: 2.2945 - accuracy: 0.1931 - val_loss: 7.8531 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.00000\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - 12s 361ms/step - loss: 2.1129 - accuracy: 0.2593 - val_loss: 9.0577 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.00000\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 1.9075 - accuracy: 0.3458 - val_loss: 10.2419 - val_accuracy: 9.4922e-04\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.00000 to 0.00095, saving model to best_model_cnn.h5\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 12s 361ms/step - loss: 1.7276 - accuracy: 0.4046 - val_loss: 10.9748 - val_accuracy: 0.0014\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.00095 to 0.00142, saving model to best_model_cnn.h5\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 12s 360ms/step - loss: 1.5396 - accuracy: 0.4876 - val_loss: 12.1808 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.00142\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 12s 360ms/step - loss: 1.3559 - accuracy: 0.5507 - val_loss: 13.0226 - val_accuracy: 0.0133\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.00142 to 0.01329, saving model to best_model_cnn.h5\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 12s 360ms/step - loss: 1.1832 - accuracy: 0.6134 - val_loss: 14.1094 - val_accuracy: 0.0019\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.01329\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 1.0248 - accuracy: 0.6735 - val_loss: 15.1358 - val_accuracy: 0.0142\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.01329 to 0.01424, saving model to best_model_cnn.h5\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 0.8708 - accuracy: 0.7331 - val_loss: 16.1179 - val_accuracy: 0.0081\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.01424\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 0.7254 - accuracy: 0.7853 - val_loss: 17.1118 - val_accuracy: 0.0408\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.01424 to 0.04082, saving model to best_model_cnn.h5\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - 12s 361ms/step - loss: 0.5928 - accuracy: 0.8405 - val_loss: 18.2933 - val_accuracy: 0.0418\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.04082 to 0.04177, saving model to best_model_cnn.h5\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.4772 - accuracy: 0.8836 - val_loss: 19.4891 - val_accuracy: 0.0327\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.04177\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.3757 - accuracy: 0.9205 - val_loss: 20.6406 - val_accuracy: 0.0266\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.04177\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 0.2898 - accuracy: 0.9467 - val_loss: 21.7105 - val_accuracy: 0.0323\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.04177\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 0.2146 - accuracy: 0.9707 - val_loss: 22.6291 - val_accuracy: 0.0375\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.04177\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.1612 - accuracy: 0.9834 - val_loss: 23.6083 - val_accuracy: 0.0375\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.04177\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 0.1168 - accuracy: 0.9911 - val_loss: 24.7424 - val_accuracy: 0.0323\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.04177\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.0889 - accuracy: 0.9937 - val_loss: 25.6843 - val_accuracy: 0.0384\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.04177\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - 12s 361ms/step - loss: 0.0699 - accuracy: 0.9950 - val_loss: 26.4141 - val_accuracy: 0.0399\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.04177\n",
            "Epoch 22/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 0.0542 - accuracy: 0.9962 - val_loss: 27.1974 - val_accuracy: 0.0408\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.04177\n",
            "Epoch 23/50\n",
            "33/33 [==============================] - 12s 360ms/step - loss: 0.0445 - accuracy: 0.9966 - val_loss: 27.8159 - val_accuracy: 0.0446\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.04177 to 0.04461, saving model to best_model_cnn.h5\n",
            "Epoch 24/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.0376 - accuracy: 0.9969 - val_loss: 28.5144 - val_accuracy: 0.0422\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.04461\n",
            "Epoch 25/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.0317 - accuracy: 0.9972 - val_loss: 28.9536 - val_accuracy: 0.0451\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.04461 to 0.04509, saving model to best_model_cnn.h5\n",
            "Epoch 26/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.0280 - accuracy: 0.9973 - val_loss: 29.6489 - val_accuracy: 0.0356\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.04509\n",
            "Epoch 27/50\n",
            "33/33 [==============================] - 12s 364ms/step - loss: 0.0241 - accuracy: 0.9974 - val_loss: 30.0731 - val_accuracy: 0.0342\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.04509\n",
            "Epoch 28/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.0225 - accuracy: 0.9976 - val_loss: 30.4434 - val_accuracy: 0.0418\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.04509\n",
            "Epoch 29/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.0206 - accuracy: 0.9969 - val_loss: 30.8782 - val_accuracy: 0.0479\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.04509 to 0.04794, saving model to best_model_cnn.h5\n",
            "Epoch 30/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.0186 - accuracy: 0.9972 - val_loss: 31.3393 - val_accuracy: 0.0356\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.04794\n",
            "Epoch 31/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.0185 - accuracy: 0.9975 - val_loss: 31.7729 - val_accuracy: 0.0332\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.04794\n",
            "Epoch 32/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.0173 - accuracy: 0.9974 - val_loss: 31.8121 - val_accuracy: 0.0437\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.04794\n",
            "Epoch 33/50\n",
            "33/33 [==============================] - 12s 361ms/step - loss: 0.0160 - accuracy: 0.9977 - val_loss: 32.4655 - val_accuracy: 0.0261\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.04794\n",
            "Epoch 34/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 0.0158 - accuracy: 0.9976 - val_loss: 32.5782 - val_accuracy: 0.0441\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.04794\n",
            "Epoch 35/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 0.0135 - accuracy: 0.9977 - val_loss: 32.9275 - val_accuracy: 0.0351\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.04794\n",
            "Epoch 36/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 0.0139 - accuracy: 0.9976 - val_loss: 32.9429 - val_accuracy: 0.0441\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.04794\n",
            "Epoch 37/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 33.3638 - val_accuracy: 0.0422\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.04794\n",
            "Epoch 38/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 0.0129 - accuracy: 0.9974 - val_loss: 33.4717 - val_accuracy: 0.0427\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.04794\n",
            "Epoch 39/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 0.0123 - accuracy: 0.9975 - val_loss: 34.0179 - val_accuracy: 0.0356\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.04794\n",
            "Epoch 40/50\n",
            "33/33 [==============================] - 12s 364ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 34.1039 - val_accuracy: 0.0441\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.04794\n",
            "Epoch 41/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 34.4486 - val_accuracy: 0.0313\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.04794\n",
            "Epoch 42/50\n",
            "33/33 [==============================] - 12s 364ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 34.7043 - val_accuracy: 0.0346\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.04794\n",
            "Epoch 43/50\n",
            "33/33 [==============================] - 12s 363ms/step - loss: 0.0126 - accuracy: 0.9975 - val_loss: 34.4678 - val_accuracy: 0.0475\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.04794\n",
            "Epoch 44/50\n",
            "33/33 [==============================] - 12s 361ms/step - loss: 0.0118 - accuracy: 0.9975 - val_loss: 34.7478 - val_accuracy: 0.0427\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.04794\n",
            "Epoch 45/50\n",
            "33/33 [==============================] - 12s 361ms/step - loss: 0.0118 - accuracy: 0.9977 - val_loss: 34.9549 - val_accuracy: 0.0451\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.04794\n",
            "Epoch 46/50\n",
            "33/33 [==============================] - 12s 361ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 35.2557 - val_accuracy: 0.0351\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.04794\n",
            "Epoch 47/50\n",
            "33/33 [==============================] - 12s 361ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 35.2350 - val_accuracy: 0.0451\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.04794\n",
            "Epoch 48/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 0.0110 - accuracy: 0.9977 - val_loss: 35.4825 - val_accuracy: 0.0413\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.04794\n",
            "Epoch 49/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 0.0111 - accuracy: 0.9975 - val_loss: 35.6772 - val_accuracy: 0.0361\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.04794\n",
            "Epoch 50/50\n",
            "33/33 [==============================] - 12s 362ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 35.5125 - val_accuracy: 0.0465\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.04794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWuUAjd2mc1J",
        "outputId": "10e9b966-4882-4d74-b306-ba695886c419"
      },
      "source": [
        "upd_history_cnn = model_cnn.fit(upd_x_train, \n",
        "                            y_train, \n",
        "                            epochs=50,\n",
        "                            batch_size=256,\n",
        "                            validation_split=0.2,\n",
        "                            callbacks=[upd_checkpoint_callback_cnn])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 8.7127 - accuracy: 0.1000 - val_loss: 4.3450 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.66667, saving model to upd_best_model_cnn.h5\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4510 - accuracy: 0.9000 - val_loss: 1.1890 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.66667\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.8239e-06 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.66667 to 1.00000, saving model to upd_best_model_cnn.h5\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.7815e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 1.00000\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 1.00000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 1.00000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 1.00000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 1.00000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 1.00000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 1.00000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 1.00000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 1.00000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 1.00000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 1.00000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 1.00000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 1.00000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 1.00000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 1.00000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 1.00000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 1.00000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 1.00000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 1.00000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 1.00000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 1.00000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 1.00000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 1.00000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 1.00000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 1.00000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 1.00000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 1.00000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 1.00000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 1.00000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 1.00000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 1.00000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 1.00000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 1.00000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 1.00000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 1.00000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 1.00000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 1.00000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 1.00000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 1.00000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 1.00000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 1.00000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 1.00000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 1.00000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 1.00000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 1.00000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 1.00000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 1.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Lk1iB1_RG_-"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "zeOzzod4oMO0",
        "outputId": "0782656f-5969-4152-d662-028d4e818c7a"
      },
      "source": [
        "plt.plot(history_cnn.history['accuracy'], \n",
        "         label='train accuracy')\n",
        "plt.plot(history_cnn.history['val_accuracy'], \n",
        "         label='test accuracy')\n",
        "plt.plot(upd_history_cnn.history['accuracy'], \n",
        "         label='upd train accuracy')\n",
        "plt.plot(upd_history_cnn.history['val_accuracy'], \n",
        "         label='upd test accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shjyj9t7nZ5Z"
      },
      "source": [
        "model_lstm = Sequential()\n",
        "model_lstm.add(Embedding(num_words, 32, input_length=max_text_len))\n",
        "model_lstm.add(LSTM(169))\n",
        "model_lstm.add(Dense(13, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMAMEGsVn6e8"
      },
      "source": [
        "model_lstm.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PiEPEK2n_KK",
        "outputId": "ac40f5d4-9d14-4a87-f19d-cbc19022d223"
      },
      "source": [
        "model_lstm.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 100, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 169)               136552    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 13)                2210      \n",
            "=================================================================\n",
            "Total params: 298,762\n",
            "Trainable params: 298,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp21Eej2oBuy"
      },
      "source": [
        "model_lstm_save_path = 'best_model_lstm.h5'\n",
        "checkpoint_callback_lstm = ModelCheckpoint(model_lstm_save_path, \n",
        "                                      monitor='val_accuracy',\n",
        "                                      save_best_only=True,\n",
        "                                      verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXKMZYNepabD"
      },
      "source": [
        "upd_model_lstm_save_path = 'upd_best_model_lstm.h5'\n",
        "upd_checkpoint_callback_lstm = ModelCheckpoint(upd_model_lstm_save_path, \n",
        "                                      monitor='val_accuracy',\n",
        "                                      save_best_only=True,\n",
        "                                      verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR4X2YszoSPv",
        "outputId": "f0e27395-bd99-4fd8-ccd0-f06eb6283c11"
      },
      "source": [
        "history_lstm = model_lstm.fit(x_train, \n",
        "                              y_train, \n",
        "                              epochs=50,\n",
        "                              batch_size=256,\n",
        "                              validation_split=0.2,\n",
        "                              callbacks=[checkpoint_callback_lstm])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "33/33 [==============================] - 58s 666ms/step - loss: 2.4412 - accuracy: 0.0969 - val_loss: 5.6207 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.00000, saving model to best_model_lstm.h5\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 21s 644ms/step - loss: 2.3830 - accuracy: 0.1011 - val_loss: 6.1223 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.00000\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 21s 635ms/step - loss: 2.3645 - accuracy: 0.1264 - val_loss: 5.2484 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.00000\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - 21s 645ms/step - loss: 2.2720 - accuracy: 0.2031 - val_loss: 5.6280 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.00000\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 21s 644ms/step - loss: 2.0954 - accuracy: 0.2700 - val_loss: 5.2818 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.00000\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 21s 647ms/step - loss: 1.8532 - accuracy: 0.3626 - val_loss: 5.6321 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.00000\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 21s 638ms/step - loss: 1.6799 - accuracy: 0.4223 - val_loss: 5.6479 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.00000\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 21s 642ms/step - loss: 1.5146 - accuracy: 0.4825 - val_loss: 6.2339 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.00000\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 21s 645ms/step - loss: 1.3982 - accuracy: 0.5191 - val_loss: 5.9116 - val_accuracy: 0.0033\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.00000 to 0.00332, saving model to best_model_lstm.h5\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 21s 642ms/step - loss: 1.2733 - accuracy: 0.5720 - val_loss: 6.2707 - val_accuracy: 0.0062\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.00332 to 0.00617, saving model to best_model_lstm.h5\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 21s 637ms/step - loss: 1.1598 - accuracy: 0.6129 - val_loss: 6.6034 - val_accuracy: 0.0109\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.00617 to 0.01092, saving model to best_model_lstm.h5\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - 21s 644ms/step - loss: 1.0754 - accuracy: 0.6488 - val_loss: 6.3544 - val_accuracy: 0.0247\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.01092 to 0.02468, saving model to best_model_lstm.h5\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - 21s 641ms/step - loss: 0.9647 - accuracy: 0.6884 - val_loss: 6.9846 - val_accuracy: 0.0308\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.02468 to 0.03085, saving model to best_model_lstm.h5\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - 21s 642ms/step - loss: 0.8718 - accuracy: 0.7202 - val_loss: 6.8515 - val_accuracy: 0.0389\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.03085 to 0.03892, saving model to best_model_lstm.h5\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - 21s 638ms/step - loss: 0.7865 - accuracy: 0.7560 - val_loss: 7.6939 - val_accuracy: 0.0327\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.03892\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - 21s 635ms/step - loss: 0.7163 - accuracy: 0.7755 - val_loss: 6.9268 - val_accuracy: 0.0422\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.03892 to 0.04224, saving model to best_model_lstm.h5\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - 21s 638ms/step - loss: 0.6304 - accuracy: 0.8065 - val_loss: 7.5800 - val_accuracy: 0.0456\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.04224 to 0.04556, saving model to best_model_lstm.h5\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - 21s 637ms/step - loss: 0.5553 - accuracy: 0.8331 - val_loss: 7.5881 - val_accuracy: 0.0513\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.04556 to 0.05126, saving model to best_model_lstm.h5\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - 21s 635ms/step - loss: 0.5030 - accuracy: 0.8515 - val_loss: 8.2006 - val_accuracy: 0.0399\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.05126\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - 21s 637ms/step - loss: 0.4468 - accuracy: 0.8707 - val_loss: 7.9222 - val_accuracy: 0.0517\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.05126 to 0.05173, saving model to best_model_lstm.h5\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - 21s 641ms/step - loss: 0.3792 - accuracy: 0.8964 - val_loss: 8.2037 - val_accuracy: 0.0422\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.05173\n",
            "Epoch 22/50\n",
            "33/33 [==============================] - 21s 646ms/step - loss: 0.3673 - accuracy: 0.8992 - val_loss: 8.3728 - val_accuracy: 0.0323\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.05173\n",
            "Epoch 23/50\n",
            "33/33 [==============================] - 21s 641ms/step - loss: 0.3077 - accuracy: 0.9195 - val_loss: 8.5548 - val_accuracy: 0.0351\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.05173\n",
            "Epoch 24/50\n",
            "33/33 [==============================] - 21s 637ms/step - loss: 0.3051 - accuracy: 0.9157 - val_loss: 8.5625 - val_accuracy: 0.0323\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.05173\n",
            "Epoch 25/50\n",
            "33/33 [==============================] - 21s 649ms/step - loss: 0.2751 - accuracy: 0.9243 - val_loss: 8.8839 - val_accuracy: 0.0361\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.05173\n",
            "Epoch 26/50\n",
            "33/33 [==============================] - 21s 643ms/step - loss: 0.2304 - accuracy: 0.9396 - val_loss: 9.1761 - val_accuracy: 0.0361\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.05173\n",
            "Epoch 27/50\n",
            "33/33 [==============================] - 21s 645ms/step - loss: 0.1982 - accuracy: 0.9497 - val_loss: 8.8479 - val_accuracy: 0.0456\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.05173\n",
            "Epoch 28/50\n",
            "33/33 [==============================] - 21s 634ms/step - loss: 0.1699 - accuracy: 0.9594 - val_loss: 9.3369 - val_accuracy: 0.0327\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.05173\n",
            "Epoch 29/50\n",
            "33/33 [==============================] - 21s 641ms/step - loss: 0.1645 - accuracy: 0.9600 - val_loss: 9.3783 - val_accuracy: 0.0432\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.05173\n",
            "Epoch 30/50\n",
            "33/33 [==============================] - 21s 645ms/step - loss: 0.1461 - accuracy: 0.9662 - val_loss: 9.2943 - val_accuracy: 0.0441\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.05173\n",
            "Epoch 31/50\n",
            "33/33 [==============================] - 21s 646ms/step - loss: 0.1183 - accuracy: 0.9733 - val_loss: 9.9390 - val_accuracy: 0.0432\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.05173\n",
            "Epoch 32/50\n",
            "33/33 [==============================] - 21s 646ms/step - loss: 0.1393 - accuracy: 0.9655 - val_loss: 8.8526 - val_accuracy: 0.0465\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.05173\n",
            "Epoch 33/50\n",
            "33/33 [==============================] - 21s 641ms/step - loss: 0.1313 - accuracy: 0.9685 - val_loss: 9.6353 - val_accuracy: 0.0337\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.05173\n",
            "Epoch 34/50\n",
            "33/33 [==============================] - 21s 639ms/step - loss: 0.1154 - accuracy: 0.9733 - val_loss: 9.5340 - val_accuracy: 0.0346\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.05173\n",
            "Epoch 35/50\n",
            "33/33 [==============================] - 21s 641ms/step - loss: 0.1212 - accuracy: 0.9699 - val_loss: 9.3698 - val_accuracy: 0.0389\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.05173\n",
            "Epoch 36/50\n",
            "33/33 [==============================] - 21s 647ms/step - loss: 0.0845 - accuracy: 0.9821 - val_loss: 10.0284 - val_accuracy: 0.0441\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.05173\n",
            "Epoch 37/50\n",
            "33/33 [==============================] - 21s 646ms/step - loss: 0.0717 - accuracy: 0.9841 - val_loss: 9.8972 - val_accuracy: 0.0370\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.05173\n",
            "Epoch 38/50\n",
            "33/33 [==============================] - 21s 643ms/step - loss: 0.0732 - accuracy: 0.9828 - val_loss: 9.4914 - val_accuracy: 0.0475\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.05173\n",
            "Epoch 39/50\n",
            "33/33 [==============================] - 21s 642ms/step - loss: 0.0812 - accuracy: 0.9811 - val_loss: 9.0359 - val_accuracy: 0.0389\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.05173\n",
            "Epoch 40/50\n",
            "33/33 [==============================] - 21s 647ms/step - loss: 0.0777 - accuracy: 0.9828 - val_loss: 10.1715 - val_accuracy: 0.0252\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.05173\n",
            "Epoch 41/50\n",
            "33/33 [==============================] - 21s 646ms/step - loss: 0.0585 - accuracy: 0.9867 - val_loss: 9.9536 - val_accuracy: 0.0337\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.05173\n",
            "Epoch 42/50\n",
            "33/33 [==============================] - 21s 645ms/step - loss: 0.0659 - accuracy: 0.9849 - val_loss: 9.5033 - val_accuracy: 0.0522\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.05173 to 0.05221, saving model to best_model_lstm.h5\n",
            "Epoch 43/50\n",
            "33/33 [==============================] - 21s 644ms/step - loss: 0.0990 - accuracy: 0.9745 - val_loss: 9.4853 - val_accuracy: 0.0451\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.05221\n",
            "Epoch 44/50\n",
            "33/33 [==============================] - 21s 646ms/step - loss: 0.0650 - accuracy: 0.9850 - val_loss: 9.5272 - val_accuracy: 0.0517\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.05221\n",
            "Epoch 45/50\n",
            "33/33 [==============================] - 21s 648ms/step - loss: 0.0562 - accuracy: 0.9884 - val_loss: 10.1792 - val_accuracy: 0.0261\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.05221\n",
            "Epoch 46/50\n",
            "33/33 [==============================] - 21s 645ms/step - loss: 0.0649 - accuracy: 0.9847 - val_loss: 10.0796 - val_accuracy: 0.0308\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.05221\n",
            "Epoch 47/50\n",
            "33/33 [==============================] - 21s 635ms/step - loss: 0.0574 - accuracy: 0.9882 - val_loss: 9.8508 - val_accuracy: 0.0451\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.05221\n",
            "Epoch 48/50\n",
            "33/33 [==============================] - 21s 640ms/step - loss: 0.0392 - accuracy: 0.9916 - val_loss: 10.1473 - val_accuracy: 0.0527\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.05221 to 0.05268, saving model to best_model_lstm.h5\n",
            "Epoch 49/50\n",
            "33/33 [==============================] - 21s 644ms/step - loss: 0.0344 - accuracy: 0.9923 - val_loss: 10.5929 - val_accuracy: 0.0380\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.05268\n",
            "Epoch 50/50\n",
            "33/33 [==============================] - 21s 639ms/step - loss: 0.0293 - accuracy: 0.9935 - val_loss: 10.4969 - val_accuracy: 0.0446\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.05268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e8qqWz_qCUu",
        "outputId": "78762257-fcbc-4812-deaa-c99a15293b51"
      },
      "source": [
        "upd_history_lstm = model_lstm.fit(upd_x_train, \n",
        "                              y_train, \n",
        "                              epochs=50,\n",
        "                              batch_size=256,\n",
        "                              validation_split=0.2,\n",
        "                              callbacks=[upd_checkpoint_callback_lstm])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 5.3266 - accuracy: 0.2000 - val_loss: 7.0694 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.00000, saving model to upd_best_model_lstm.h5\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 2.7138 - accuracy: 0.6000 - val_loss: 4.3280 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.00000\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.6184 - accuracy: 0.9000 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.00000 to 1.00000, saving model to upd_best_model_lstm.h5\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.4109 - accuracy: 0.9000 - val_loss: 3.0112e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 1.00000\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 7.5707e-05 - accuracy: 1.0000 - val_loss: 4.6052e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 1.00000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 7.1525e-07 - accuracy: 1.0000 - val_loss: 1.2676e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 1.00000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 2.7418e-07 - accuracy: 1.0000 - val_loss: 4.8876e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 1.00000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 1.4305e-07 - accuracy: 1.0000 - val_loss: 2.3444e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 1.00000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 7.1526e-08 - accuracy: 1.0000 - val_loss: 1.3510e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 1.00000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 3.5763e-08 - accuracy: 1.0000 - val_loss: 8.3446e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 1.00000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 1.1921e-08 - accuracy: 1.0000 - val_loss: 5.9605e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 1.00000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7684e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 1.00000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 1.00000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.1789e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 1.00000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.3842e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 1.00000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.3842e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 1.00000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9868e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 1.00000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9868e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 1.00000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9868e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 1.00000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9868e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 1.00000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9868e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 1.00000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5895e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 1.00000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5895e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 1.00000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9868e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 1.00000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9868e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 1.00000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9868e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 1.00000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9868e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 1.00000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9868e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 1.00000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 1.00000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 1.00000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 1.00000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 1.00000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 1.00000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 1.00000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 1.00000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 1.00000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 1.00000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 1.00000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 1.00000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 1.00000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 1.00000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 1.00000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 1.00000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 1.00000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 1.00000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 1.00000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 1.00000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 1.00000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 1.00000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 1.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "dmJmU86YoX4s",
        "outputId": "a5e81f63-4886-4180-94ee-cb46131b9897"
      },
      "source": [
        "plt.plot(history_lstm.history['accuracy'], \n",
        "         label='train accuracy')\n",
        "plt.plot(history_lstm.history['val_accuracy'], \n",
        "         label='test accuracy')\n",
        "plt.plot(upd_history_lstm.history['accuracy'], \n",
        "         label='upd train accuracy')\n",
        "plt.plot(upd_history_lstm.history['val_accuracy'], \n",
        "         label='upd test accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrcHveiHodga"
      },
      "source": [
        "model_gru = Sequential()\n",
        "model_gru.add(Embedding(num_words, 32, input_length=max_text_len))\n",
        "model_gru.add(GRU(169))\n",
        "model_gru.add(Dense(13, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO4-vG_Joh1p"
      },
      "source": [
        "model_gru.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1wOoKhJokmc",
        "outputId": "177e575b-d092-4610-96bc-faf3532e8113"
      },
      "source": [
        "model_gru.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 100, 32)           160000    \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 169)               102921    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 13)                2210      \n",
            "=================================================================\n",
            "Total params: 265,131\n",
            "Trainable params: 265,131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5JspntRonFX"
      },
      "source": [
        "model_gru_save_path = 'best_model_gru.h5'\n",
        "checkpoint_callback_gru = ModelCheckpoint(model_gru_save_path, \n",
        "                                      monitor='val_accuracy',\n",
        "                                      save_best_only=True,\n",
        "                                      verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3oziK4EuggH"
      },
      "source": [
        "upd_model_gru_save_path = 'upd_best_model_gru.h5'\n",
        "upd_checkpoint_callback_gru = ModelCheckpoint(upd_model_gru_save_path, \n",
        "                                      monitor='val_accuracy',\n",
        "                                      save_best_only=True,\n",
        "                                      verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjwAEIBdu0R9",
        "outputId": "9db41fb4-29df-459f-9b86-293dcea7f984"
      },
      "source": [
        "upd_history_gru = model_gru.fit(upd_x_train, \n",
        "                              y_train, \n",
        "                              epochs=50,\n",
        "                              batch_size=256,\n",
        "                              validation_split=0.2,\n",
        "                              callbacks=[upd_checkpoint_callback_gru])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.5650 - accuracy: 0.0000e+00 - val_loss: 2.5354 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.66667, saving model to upd_best_model_gru.h5\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.5337 - accuracy: 1.0000 - val_loss: 2.5094 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.66667 to 1.00000, saving model to upd_best_model_gru.h5\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.5004 - accuracy: 1.0000 - val_loss: 2.4788 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 1.00000\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.4624 - accuracy: 1.0000 - val_loss: 2.4418 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 1.00000\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.4176 - accuracy: 1.0000 - val_loss: 2.3959 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 1.00000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.3632 - accuracy: 1.0000 - val_loss: 2.3380 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 1.00000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.2957 - accuracy: 1.0000 - val_loss: 2.2632 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 1.00000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 2.2100 - accuracy: 1.0000 - val_loss: 2.1640 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 1.00000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 2.0982 - accuracy: 1.0000 - val_loss: 2.0274 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 1.00000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 1.9473 - accuracy: 1.0000 - val_loss: 1.8299 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 1.00000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.7338 - accuracy: 1.0000 - val_loss: 1.5228 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 1.00000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 1.4115 - accuracy: 1.0000 - val_loss: 0.9888 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 1.00000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.8776 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 1.00000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 1.3156e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 1.00000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 1.1523e-04 - accuracy: 1.0000 - val_loss: 1.4146e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 1.00000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 1.2910e-05 - accuracy: 1.0000 - val_loss: 3.8147e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 1.00000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 3.5644e-06 - accuracy: 1.0000 - val_loss: 1.5497e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 1.00000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 1.4305e-06 - accuracy: 1.0000 - val_loss: 8.3446e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 1.00000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 7.1526e-07 - accuracy: 1.0000 - val_loss: 5.9605e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 1.00000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 5.9605e-07 - accuracy: 1.0000 - val_loss: 2.3842e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 1.00000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.3842e-07 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 1.00000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 1.00000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 1.00000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 1.00000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 1.00000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 1.00000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 1.00000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 1.00000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 1.00000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 1.00000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 1.00000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 1.00000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 1.00000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 1.00000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 1.00000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 1.00000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 1.00000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 1.00000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 1.00000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 1.00000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 1.00000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 1.00000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 1.00000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 1.00000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 1.00000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 1.00000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 1.00000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 1.00000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 1.00000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 1.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OseyChqDoqNb",
        "outputId": "b8fe1fc1-4f9c-4879-da1d-1fd8a9df92cf"
      },
      "source": [
        "history_gru = model_gru.fit(x_train, \n",
        "                              y_train, \n",
        "                              epochs=50,\n",
        "                              batch_size=256,\n",
        "                              validation_split=0.2,\n",
        "                              callbacks=[checkpoint_callback_gru])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "33/33 [==============================] - 18s 536ms/step - loss: 8.6024 - accuracy: 0.0946 - val_loss: 2.7080 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.00000, saving model to best_model_gru.h5\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 17s 532ms/step - loss: 2.5087 - accuracy: 0.1174 - val_loss: 3.0066 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.00000\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 17s 529ms/step - loss: 2.4445 - accuracy: 0.1525 - val_loss: 3.6813 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.00000\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - 17s 528ms/step - loss: 2.3767 - accuracy: 0.1850 - val_loss: 4.9166 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.00000\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 17s 527ms/step - loss: 2.3187 - accuracy: 0.2821 - val_loss: 5.9582 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.00000\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 17s 530ms/step - loss: 2.2407 - accuracy: 0.3333 - val_loss: 6.6836 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.00000\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 17s 529ms/step - loss: 2.1325 - accuracy: 0.3545 - val_loss: 7.0331 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.00000\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 18s 535ms/step - loss: 2.0032 - accuracy: 0.3766 - val_loss: 7.1069 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.00000\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 17s 531ms/step - loss: 1.8626 - accuracy: 0.4032 - val_loss: 7.3644 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.00000\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 17s 531ms/step - loss: 1.7190 - accuracy: 0.4311 - val_loss: 7.3336 - val_accuracy: 9.4922e-04\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.00000 to 0.00095, saving model to best_model_gru.h5\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 17s 531ms/step - loss: 1.5698 - accuracy: 0.4847 - val_loss: 7.4089 - val_accuracy: 0.0033\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.00095 to 0.00332, saving model to best_model_gru.h5\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - 17s 526ms/step - loss: 1.4363 - accuracy: 0.5252 - val_loss: 7.4551 - val_accuracy: 0.0066\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.00332 to 0.00664, saving model to best_model_gru.h5\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - 17s 529ms/step - loss: 1.3230 - accuracy: 0.5595 - val_loss: 6.8090 - val_accuracy: 0.0138\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.00664 to 0.01376, saving model to best_model_gru.h5\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - 17s 528ms/step - loss: 1.2111 - accuracy: 0.6006 - val_loss: 7.3957 - val_accuracy: 0.0152\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.01376 to 0.01519, saving model to best_model_gru.h5\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - 17s 530ms/step - loss: 1.1191 - accuracy: 0.6311 - val_loss: 7.2446 - val_accuracy: 0.0190\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.01519 to 0.01898, saving model to best_model_gru.h5\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - 17s 528ms/step - loss: 1.0282 - accuracy: 0.6607 - val_loss: 7.5892 - val_accuracy: 0.0185\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.01898\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - 17s 528ms/step - loss: 0.9374 - accuracy: 0.6918 - val_loss: 7.9698 - val_accuracy: 0.0166\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.01898\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - 17s 530ms/step - loss: 0.8665 - accuracy: 0.7236 - val_loss: 7.8904 - val_accuracy: 0.0166\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.01898\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - 17s 527ms/step - loss: 0.7846 - accuracy: 0.7509 - val_loss: 8.1945 - val_accuracy: 0.0209\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.01898 to 0.02088, saving model to best_model_gru.h5\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - 17s 531ms/step - loss: 0.7371 - accuracy: 0.7687 - val_loss: 8.1187 - val_accuracy: 0.0218\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.02088 to 0.02183, saving model to best_model_gru.h5\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - 17s 528ms/step - loss: 0.6716 - accuracy: 0.7905 - val_loss: 8.3302 - val_accuracy: 0.0247\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.02183 to 0.02468, saving model to best_model_gru.h5\n",
            "Epoch 22/50\n",
            "33/33 [==============================] - 17s 528ms/step - loss: 0.6104 - accuracy: 0.8114 - val_loss: 8.8463 - val_accuracy: 0.0190\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.02468\n",
            "Epoch 23/50\n",
            "33/33 [==============================] - 18s 532ms/step - loss: 0.5532 - accuracy: 0.8347 - val_loss: 8.5430 - val_accuracy: 0.0256\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.02468 to 0.02563, saving model to best_model_gru.h5\n",
            "Epoch 24/50\n",
            "33/33 [==============================] - 17s 531ms/step - loss: 0.5090 - accuracy: 0.8476 - val_loss: 9.0247 - val_accuracy: 0.0209\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.02563\n",
            "Epoch 25/50\n",
            "33/33 [==============================] - 18s 532ms/step - loss: 0.4771 - accuracy: 0.8614 - val_loss: 9.1889 - val_accuracy: 0.0242\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.02563\n",
            "Epoch 26/50\n",
            "33/33 [==============================] - 17s 530ms/step - loss: 0.4235 - accuracy: 0.8794 - val_loss: 9.1235 - val_accuracy: 0.0299\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.02563 to 0.02990, saving model to best_model_gru.h5\n",
            "Epoch 27/50\n",
            "33/33 [==============================] - 18s 533ms/step - loss: 0.3755 - accuracy: 0.8990 - val_loss: 9.3690 - val_accuracy: 0.0299\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.02990\n",
            "Epoch 28/50\n",
            "33/33 [==============================] - 18s 532ms/step - loss: 0.3376 - accuracy: 0.9090 - val_loss: 9.4553 - val_accuracy: 0.0323\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.02990 to 0.03227, saving model to best_model_gru.h5\n",
            "Epoch 29/50\n",
            "33/33 [==============================] - 18s 531ms/step - loss: 0.3299 - accuracy: 0.9115 - val_loss: 9.4495 - val_accuracy: 0.0342\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.03227 to 0.03417, saving model to best_model_gru.h5\n",
            "Epoch 30/50\n",
            "33/33 [==============================] - 17s 530ms/step - loss: 0.3016 - accuracy: 0.9223 - val_loss: 9.6842 - val_accuracy: 0.0323\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.03417\n",
            "Epoch 31/50\n",
            "33/33 [==============================] - 17s 531ms/step - loss: 0.2805 - accuracy: 0.9258 - val_loss: 9.7849 - val_accuracy: 0.0304\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.03417\n",
            "Epoch 32/50\n",
            "33/33 [==============================] - 18s 536ms/step - loss: 0.2419 - accuracy: 0.9435 - val_loss: 9.8273 - val_accuracy: 0.0332\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.03417\n",
            "Epoch 33/50\n",
            "33/33 [==============================] - 17s 530ms/step - loss: 0.2278 - accuracy: 0.9453 - val_loss: 9.8052 - val_accuracy: 0.0356\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.03417 to 0.03560, saving model to best_model_gru.h5\n",
            "Epoch 34/50\n",
            "33/33 [==============================] - 18s 536ms/step - loss: 0.2044 - accuracy: 0.9518 - val_loss: 10.0965 - val_accuracy: 0.0342\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.03560\n",
            "Epoch 35/50\n",
            "33/33 [==============================] - 18s 535ms/step - loss: 0.2046 - accuracy: 0.9501 - val_loss: 10.0477 - val_accuracy: 0.0294\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.03560\n",
            "Epoch 36/50\n",
            "33/33 [==============================] - 18s 533ms/step - loss: 0.1638 - accuracy: 0.9657 - val_loss: 10.3241 - val_accuracy: 0.0323\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.03560\n",
            "Epoch 37/50\n",
            "33/33 [==============================] - 18s 533ms/step - loss: 0.1527 - accuracy: 0.9683 - val_loss: 10.4604 - val_accuracy: 0.0327\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.03560\n",
            "Epoch 38/50\n",
            "33/33 [==============================] - 18s 534ms/step - loss: 0.1284 - accuracy: 0.9764 - val_loss: 10.5397 - val_accuracy: 0.0356\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.03560\n",
            "Epoch 39/50\n",
            "33/33 [==============================] - 18s 536ms/step - loss: 0.1127 - accuracy: 0.9805 - val_loss: 10.8336 - val_accuracy: 0.0323\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.03560\n",
            "Epoch 40/50\n",
            "33/33 [==============================] - 18s 538ms/step - loss: 0.1045 - accuracy: 0.9814 - val_loss: 10.9043 - val_accuracy: 0.0380\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.03560 to 0.03797, saving model to best_model_gru.h5\n",
            "Epoch 41/50\n",
            "33/33 [==============================] - 18s 537ms/step - loss: 0.1052 - accuracy: 0.9799 - val_loss: 11.0179 - val_accuracy: 0.0365\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.03797\n",
            "Epoch 42/50\n",
            "33/33 [==============================] - 18s 539ms/step - loss: 0.0915 - accuracy: 0.9839 - val_loss: 11.0112 - val_accuracy: 0.0356\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.03797\n",
            "Epoch 43/50\n",
            "33/33 [==============================] - 18s 535ms/step - loss: 0.0758 - accuracy: 0.9879 - val_loss: 11.3069 - val_accuracy: 0.0342\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.03797\n",
            "Epoch 44/50\n",
            "33/33 [==============================] - 18s 534ms/step - loss: 0.0710 - accuracy: 0.9891 - val_loss: 11.4346 - val_accuracy: 0.0304\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.03797\n",
            "Epoch 45/50\n",
            "33/33 [==============================] - 17s 529ms/step - loss: 0.0702 - accuracy: 0.9891 - val_loss: 11.4072 - val_accuracy: 0.0403\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.03797 to 0.04034, saving model to best_model_gru.h5\n",
            "Epoch 46/50\n",
            "33/33 [==============================] - 18s 536ms/step - loss: 0.0717 - accuracy: 0.9874 - val_loss: 11.4401 - val_accuracy: 0.0327\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.04034\n",
            "Epoch 47/50\n",
            "33/33 [==============================] - 18s 540ms/step - loss: 0.0796 - accuracy: 0.9841 - val_loss: 11.5924 - val_accuracy: 0.0304\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.04034\n",
            "Epoch 48/50\n",
            "33/33 [==============================] - 18s 536ms/step - loss: 0.0750 - accuracy: 0.9861 - val_loss: 11.2543 - val_accuracy: 0.0422\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.04034 to 0.04224, saving model to best_model_gru.h5\n",
            "Epoch 49/50\n",
            "33/33 [==============================] - 18s 534ms/step - loss: 0.0636 - accuracy: 0.9896 - val_loss: 11.8975 - val_accuracy: 0.0290\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.04224\n",
            "Epoch 50/50\n",
            "33/33 [==============================] - 18s 534ms/step - loss: 0.0805 - accuracy: 0.9831 - val_loss: 11.4423 - val_accuracy: 0.0394\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.04224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "vFfVyZF8vGHw",
        "outputId": "5ed1c946-6fca-4bb7-9ee9-5e91589c6bbc"
      },
      "source": [
        "plt.plot(history_gru.history['accuracy'], \n",
        "         label='train accuracy')\n",
        "plt.plot(history_gru.history['val_accuracy'], \n",
        "         label='test accuracy')\n",
        "plt.plot(upd_history_gru.history['accuracy'], \n",
        "         label='upd train accuracy')\n",
        "plt.plot(upd_history_gru.history['val_accuracy'], \n",
        "         label='upd test accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCo1BEBwx0s0"
      },
      "source": [
        "x_test = test['MESSAGE']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFk-H0MryIVB",
        "outputId": "9e91cdc3-1382-4d92-b15d-c31a383e022b"
      },
      "source": [
        "upd_x_test = []\n",
        "i = 0\n",
        "\n",
        "while i<file_names_size:\n",
        "  upd_test = token_and_stem(x_test[i])\n",
        "  upd_x_test.append(upd_test)\n",
        "  i = i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NrlczLsxuQJ"
      },
      "source": [
        "tokens = []\n",
        "test = []\n",
        "\n",
        "for x_tr in upd_x_test:\n",
        "  for token in x_tr:\n",
        "    if token not in stopwords:\n",
        "      tokens.append(token)\n",
        "  test.append(tokens)\n",
        "  tokens = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhnKYxpWyebE"
      },
      "source": [
        "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
        "upd_test_sequences = upd_tokenizer.texts_to_sequences(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZDiFEw6o0g6"
      },
      "source": [
        "x_test = pad_sequences(test_sequences, maxlen=max_text_len)\n",
        "upd_x_test = pad_sequences(upd_test_sequences, maxlen=max_text_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgfYdredo2nf"
      },
      "source": [
        "y_test = utils.to_categorical(test['THEME'],file_names_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKjQOHYNo40j",
        "outputId": "613873ab-561f-4ca9-b104-9925cf516572"
      },
      "source": [
        "model_cnn.load_weights(model_cnn_save_path)\n",
        "model_cnn.evaluate(x_test, y_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - 1s 10ms/step - loss: 10.0252 - accuracy: 0.3033\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10.02521800994873, 0.30326005816459656]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Kg0N5Pglo6wC",
        "outputId": "e74462d0-62cd-4c34-8586-bc4cf4dddb0f"
      },
      "source": [
        "model_cnn.load_weights(upd_model_cnn_save_path)\n",
        "model_cnn.evaluate(upd_x_test, y_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-cfc374e2bfe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupd_model_cnn_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupd_x_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1647\u001b[0m           label, \", \".join(str(i.shape[0]) for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1648\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 13\n  y sizes: 2638\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaD1D7Gwo9Na"
      },
      "source": [
        "model_lstm.load_weights(model_lstm_save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wftu4Gz6o_uC",
        "outputId": "16bb4740-5e56-44b5-fbc7-b16a38b5c86f"
      },
      "source": [
        "model_lstm.evaluate(x_test, y_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - 4s 53ms/step - loss: 5.8177 - accuracy: 0.2820\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.817650318145752, 0.2820318341255188]"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWo03kTppDB6"
      },
      "source": [
        "model_gru.load_weights(model_gru_save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eld7uiOdpE43",
        "outputId": "e7dc8c95-9ccb-4f18-c9a6-d1b6228b6bbf"
      },
      "source": [
        "model_gru.evaluate(x_test, y_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - 2s 30ms/step - loss: 6.8351 - accuracy: 0.2005\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.835122108459473, 0.20053070783615112]"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eOT53VtpHDf"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}